<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cv on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/cv/</link>
    <description>Recent content in cv on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Sat, 26 Jun 2021 10:35:58 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>炼丹杂记 -- 低版本 PyTorch 中 pack_padded_sequence 缺少 enforce_sorted 参数问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp7/</link>
      <pubDate>Sat, 26 Jun 2021 10:35:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp7/</guid>
      <description>背景 近期用到了一台新的堡垒机，上面的驱动环境比较老只能用 1.0.0 版本的 PyTorch。 调试了代码以后发现大体上没有遇到什么问题，唯一就是涉及到 GRU 的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Learning in the Frequency Domain (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn20/</link>
      <pubDate>Fri, 25 Jun 2021 15:44:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn20/</guid>
      <description>Learning in the Frequency Domain (CVPR 2020) 出发点 受计算资源与内存限制，大多数 CNN 模型只用低分辨率的 RGB 图像作为输入，处理现实中高分辨率图像时要先缩小尺寸，而这一过程难免带来</description>
    </item>
    
    <item>
      <title>Latex 希腊字母</title>
      <link>http://jonathanwayy.xyz/2021/latex_greeceletter/</link>
      <pubDate>Fri, 25 Jun 2021 11:30:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_greeceletter/</guid>
      <description>记录一下 Latex 中的希腊字母实现，以备查用。 小写 代码 大写 代码 \(\alpha\) \alpha \(\Alpha\) \(A\) \Alpha A \(\beta\) \beta \(\Beta\) \(B\) \Beta B \(\gamma\) \gamma \(\Gamma\) \Gamma \(\delta\) \delta \(\Delta\) \Delta \(\epsilon\) \(\varepsilon\) \epsilon \varepsilon \(\Epsilon\) \(E\) \Epsilon E \(\zeta\) \zeta \(\Zeta\) \(Z\) \Zeta Z \(\eta\) \eta \(\Eta\) \(H\) \Eta H \(\theta\) \(\vartheta\) \theta</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 带限函数</title>
      <link>http://jonathanwayy.xyz/2021/ldp6/</link>
      <pubDate>Thu, 24 Jun 2021 22:32:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp6/</guid>
      <description>定义 若一个函数对于以原点为中心的有限区间（带宽） \([-\mu_{max}, \mu_{max}]\)以外的频率值，其傅里叶变换均为 0，则称之为带限函数*。*</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 卷积定理</title>
      <link>http://jonathanwayy.xyz/2021/conv-theory/</link>
      <pubDate>Thu, 24 Jun 2021 21:23:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/conv-theory/</guid>
      <description>卷积定义 用算子 \(\star\) 表示两个函数的卷积，定义为 $$(f \star h)(t) = \int_{-\infty}^{\infty} f(\tau)h(t-\tau)d\tau.$$ 卷积定理 空间域中两个函数的卷积的傅里叶变换，等于频率域中两个函数傅里叶变换的乘积。反过</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Graph Convolutional Network Hashing (IJCAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn19/</link>
      <pubDate>Thu, 24 Jun 2021 15:26:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn19/</guid>
      <description>Graph Convolutional Network Hashing for Cross-Modal Retrieval (IJCAI 2019) 本文提出一种针对跨模态检索的图卷积网络哈希 (graph convolution network hashing, GCH)，由一个语义编码器、两个特征编码网络和一个基于融合模块的图卷积网</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- ValueError: only one element tensors can be converted to Python scalars 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp5/</link>
      <pubDate>Thu, 24 Jun 2021 00:01:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp5/</guid>
      <description>问题描述 形如以下操作： lst = [] a, b = torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]) lst.append(a) lst.append(b) converted_lst = torch.tensor(lst) 得到如下报错信息： ValueError: only one element tensors can be converted to Python scalars 原因分析 元素为 tensor 的 list 无法转化为 tensor。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-modal Scene Graph Matching (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn18/</link>
      <pubDate>Wed, 23 Jun 2021 09:36:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn18/</guid>
      <description>Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval (WACV 2020) 出发点 正确的匹配除了要包含相同的目标以外，目标之间的关系也应当相同。 因而，本文使用视觉场景图 (visual scene graph, VSG) 和文本场景图 (textual scene graph, TSG)</description>
    </item>
    
    <item>
      <title>Latex 分段函数的一种实现方式</title>
      <link>http://jonathanwayy.xyz/2021/latex_case/</link>
      <pubDate>Tue, 22 Jun 2021 21:05:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_case/</guid>
      <description>代码实现 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\\\ -3x, \quad if \ x \le 1.\end{cases}$$ 呈现效果 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\ -3x, \quad if \ x \le 1.\end{cases}$$</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-Modal Center Loss (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn17/</link>
      <pubDate>Tue, 22 Jun 2021 19:53:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn17/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 现有方法的问题 核心思想是最小化由预训练网络提取的多模态特征之间的跨模态差异，而这些预训练网络应当与跨模态数据联合训练 现有的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Deep Cross-Modal Hashing (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn16/</link>
      <pubDate>Tue, 22 Jun 2021 16:33:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn16/</guid>
      <description>Deep Cross-Modal Hashing (CVPR 2017) 哈希的目标 将原始空间数据点映射为汉明空间中的二进制编码，在汉明空间中保留原始空间中的相似度。 两类多模态哈希 (Multi-Modal Hashing, MMH) 多源哈希 (multi-source hashing, MSH) 目的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Self-Supervised Adversarial Hashing Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn15/</link>
      <pubDate>Tue, 22 Jun 2021 10:54:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn15/</guid>
      <description>Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval (CVPR 2018) 当前(当时)跨模态哈希方法的主要不足 直接使用单类标签来衡量跨模态的语义关联，而事实上标准的跨模态数据集中一个图像实例往往能</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] AXM-Net: Cross-Modal Context Sharing Attention Network (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn14/</link>
      <pubDate>Mon, 21 Jun 2021 14:24:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn14/</guid>
      <description>2101.08238 AXM-Net: Cross-Modal Context Sharing Attention Network for Person Re-ID (2021) 主要困难 各模态中与行人相关的信息结构相当不同 关键在于学习一个能够从数据中提取语义的网络，而不是在训练过程中简单记住各行</description>
    </item>
    
    <item>
      <title>Latex 公式中的空格表示</title>
      <link>http://jonathanwayy.xyz/2021/latex_space/</link>
      <pubDate>Mon, 21 Jun 2021 14:11:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_space/</guid>
      <description>类型 代码 效果 备注 两个 quad 空格 a \qquad b \(a \qquad b\) 两个 M 的宽度 quad 空格 a \quad b \(a \quad b\) 一个 M 的宽度 大空格 a\ b \(a \ b\) 1/3 M 的宽度 中等空格 a\;b \(a \; b\) 2/7 M 的宽度 小空格 a\,b</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] FcaNet: Frequency Channel Attention Networks (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn13/</link>
      <pubDate>Sun, 20 Jun 2021 14:25:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn13/</guid>
      <description>2012.11879 FcaNet: Frequency Channel Attention Networks (2020) 利用频率分析重新思索通道注意力，并从数学上证明传统的全局平均池化 (GAP) 是频域中特征分解的一种特殊情况。 GAP 的潜在问题 尽管简洁高效， GAP</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Deep Adversarial Graph Attention Convolution Network (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn12/</link>
      <pubDate>Thu, 17 Jun 2021 20:35:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn12/</guid>
      <description>Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search (MM 2019) 先前工作的问题 孤立对待图像中的局部块，只考虑文本描述中单词级别的上下文关联，因而忽略了图文所包含的结构化语义信息 (structured semantic</description>
    </item>
    
    <item>
      <title>Latex 插入空行</title>
      <link>http://jonathanwayy.xyz/2021/latex_spaceline/</link>
      <pubDate>Wed, 16 Jun 2021 20:38:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_spaceline/</guid>
      <description>有时需要在 Latex 文档中插入一个空行，查阅一些文档并做了一些尝试后，发现了一种较为简单的方法： \\ \hspace*{\fill} \\ 即换行，用空格填充后，再次换行。</description>
    </item>
    
    <item>
      <title>Latex 取消段首缩进</title>
      <link>http://jonathanwayy.xyz/2021/latex_noindent/</link>
      <pubDate>Wed, 16 Jun 2021 20:28:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_noindent/</guid>
      <description>要取消 Latex 段首缩进，可以在需要处理的段落前加上如下代码： \noindent</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIPCB: A Simple but Effective Part-based Convolutional Baseline</title>
      <link>http://jonathanwayy.xyz/2021/prn11/</link>
      <pubDate>Tue, 15 Jun 2021 13:42:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn11/</guid>
      <description>2105.11628 TIPCB: A Simple but Effective Part-based Convolutional Baseline for Text-based Person Search 视觉特征学习 在视觉 CNN 分支，ResNet-50 第 3 和第 4 个残差块的输出分别作为低级特征图和高级特征图。 用 GMP 聚合低级特</description>
    </item>
    
    <item>
      <title>Matplotlib 颜色表</title>
      <link>http://jonathanwayy.xyz/2021/matplotlib-color/</link>
      <pubDate>Sun, 06 Jun 2021 16:46:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/matplotlib-color/</guid>
      <description>Matplotlib 中的颜色表如下图所示，可以直接通过参数color=&#39;颜色名称&#39;选取对应的颜色。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Reasoning with Heterogeneous Graph Alignment (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn10/</link>
      <pubDate>Thu, 03 Jun 2021 18:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn10/</guid>
      <description>Reasoning with Heterogeneous Graph Alignment for Video Question Answering 出发点 需要一个统一的方法同步对模态间和模态内的关联性进行建模与推理。 本文所提到的 “视频段 (video shot)” 指的是一小段能被 3D 卷</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Object-Centric Representation Learning (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn9/</link>
      <pubDate>Tue, 01 Jun 2021 09:48:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn9/</guid>
      <description>2104.05166 Object-Centric Representation Learning for Video Question Answering 模型高训练度带来的问题 这类模型更倾向于捕捉浅层模式 (shallow patterns)，因而会在浅层统计量形成捷径 (creating shortcuts through surface statistic</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Location-Aware Graph Convolutional Networks (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn8/</link>
      <pubDate>Sun, 30 May 2021 14:39:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn8/</guid>
      <description>Location-aware graph convolutional networks for video question answering (AAAI 2020) 与 IQA 相比 VQA 的几个困难 由于视频包含大量帧，其视觉内容更为复杂，尤其是其中一些帧主要被与问题无关的背景内容 (strong background content) 占据 视频通常</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn7/</link>
      <pubDate>Sat, 29 May 2021 14:57:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn7/</guid>
      <description>Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering (AAAI 2019) RNN + Attention 方法问题 耗时 由于 RNN 的特点，难以建模长距离依赖关系 本文提出了一个名为 Positional Self-Attention with Co-attention (PSAC) 的新架构，是首个无需使用 RNN 的模型。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Consensus-Aware Visual-Semantic Embedding (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn6/</link>
      <pubDate>Sat, 29 May 2021 10:55:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn6/</guid>
      <description>2007.08883 Consensus-Aware Visual-Semantic Embedding for Image-Text Matching (ECCV 2020) 当前主流方法 将图像与文本投影到一个公共空间，通常无法充分利用图像中目标以及句子段之间的关系 分块级别的匹配 (fragment-level matching) + 聚合其相似度</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Learnable Aggregating Net with Diversity Learning (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn5/</link>
      <pubDate>Fri, 28 May 2021 19:43:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn5/</guid>
      <description>Learnable Aggregating Net with Diversity Learning for Video Question Answering (MM 2019) V-VQA 三个难点 视频通常包含大量冗余信息 一些视频相关问题涉及多个关键帧，较难定位 有效聚合视频与句子特征以捕捉回答真实分布的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Structured Two-stream Attention Network (AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn4/</link>
      <pubDate>Fri, 28 May 2021 15:21:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn4/</guid>
      <description>Structured two-stream attention network for video question answering (AAAI 2019) 图像 QA 中两种注意力机制 visual attention: &amp;ldquo;where to look&amp;rdquo; question attention: &amp;ldquo;what words to listen to&amp;rdquo; 视频 QA 三个主要困难 考虑长距离时域结构，同时不遗漏重要信息 为了定位相关视频实</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn3/</link>
      <pubDate>Fri, 28 May 2021 14:06:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn3/</guid>
      <description>Motion-Appearance Co-Memory Networks for Video Question Answering (CVPR 2018) 视频 QA 与 图像 QA 相比三个独有特性 处理较长的图像序列，包含更丰富的信息（数量上及多样性上） 动作与外观信息通常互相关联，能够彼此</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn2/</link>
      <pubDate>Thu, 27 May 2021 13:55:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn2/</guid>
      <description>Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17) 延伸模型的缺陷 由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息 这些模型将整个问题编码为单一特征，不具有足够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn1/</link>
      <pubDate>Thu, 27 May 2021 13:49:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn1/</guid>
      <description>Tgif-qa: Toward spatio-temporal reasoning in visual question answering (CVPR 2017) 开源代码传送门 三点重要贡献 提出专为视频 VQA 设计的三种新任务，需要对视频的时空推断(spatio-temporal reaso</description>
    </item>
    
    <item>
      <title>OpenCV 与 PIL.Image 之间的图像通道（channel）转换</title>
      <link>http://jonathanwayy.xyz/2021/opencv-pil-channel/</link>
      <pubDate>Fri, 14 May 2021 19:46:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/opencv-pil-channel/</guid>
      <description>今天有学弟提到了一个打开图像并显示时图像色调变蓝的问题，经历一番周折后最终解决，在此记录。 问题的根本原因在于 OpenCV 默认是以 BGR 的通道顺序打开和显示</description>
    </item>
    
    <item>
      <title>辛格函数 sinc 杂记</title>
      <link>http://jonathanwayy.xyz/2021/sinc/</link>
      <pubDate>Mon, 10 May 2021 13:21:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/sinc/</guid>
      <description>sinc 函数在不同领域有不同的定义，用符号 \(sinc(x)\) 表示，可被定义为归一化的或者非归一化的，不过两种函数都是正弦函数和单调递减函数 \(\frac{1}{x}\) 的乘积。 数字信号处理和</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch view 函数 RuntimeError 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp4/</link>
      <pubDate>Sat, 08 May 2021 18:37:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp4/</guid>
      <description>问题描述 在程序中使用形如 A = X.view(32, -1) 的语句调用 view 时出现如下报错： RuntimeError: view size is not compatible with input tensor&#39;s size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. 原因分析 view() 需要 Tensor 中元素地址连续，</description>
    </item>
    
    <item>
      <title>ACM 会议论文模板去除 ACM Reference Format 信息</title>
      <link>http://jonathanwayy.xyz/2021/latex_acmtem/</link>
      <pubDate>Fri, 16 Apr 2021 18:48:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_acmtem/</guid>
      <description>在投稿撰文时，可以去掉 ACM 的 latex 模板中会有的 ACM Reference Format 信息。 方法如下： 在 \documentclass[sigconf]{acmart} 下面添加以下几行： \settopmatter{printacmref=false} % Removes citation information below abstract \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column \pagestyle{plain} % removes running headers</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- GELU 激活函数的 Pytorch 实现</title>
      <link>http://jonathanwayy.xyz/2021/ldp3/</link>
      <pubDate>Thu, 25 Mar 2021 17:48:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp3/</guid>
      <description>Transformers 中提出了一个新的激活函数 GELU，由于比较新，该模块仅在 1.8 以上版本的 Pytorch 中被收录。 要在较低版本的 Pytorch 中使用 GELU，可自行编写实现，代码如下：</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- nvidia-smi指令报错：Failed to initialize NVML 解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp2/</link>
      <pubDate>Fri, 22 Jan 2021 14:27:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp2/</guid>
      <description>问题描述 使用指令 nvidia-smi 时报错： Failed to initialize NVML: Driver/library version mismatch 问题原因 NVIDIA 内核驱动版本与系统驱动不一致。 解决办法 网上有很多调整驱动版本的方法教程，但其实最简单的方法</description>
    </item>
    
    <item>
      <title>BLWL[37] 简单干净卸载 cuda 的方法</title>
      <link>http://jonathanwayy.xyz/2020/blwl37/</link>
      <pubDate>Sat, 19 Dec 2020 21:00:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl37/</guid>
      <description>网上有各种有关如何通过一系列命令卸载 cuda 的教程，但其实 cuda 是自带卸载脚本的。 第一步： 找到 cuda 所在路径 cuda 位于 /usr/local/cuda/bin 目录下。 进入目录后运行卸载脚本： sudo ./uninstall_cuda_10.0.pl 第</description>
    </item>
    
    <item>
      <title>通过 Conda 安装 Python OpenCV</title>
      <link>http://jonathanwayy.xyz/2020/conda-opencv/</link>
      <pubDate>Fri, 18 Dec 2020 00:33:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/conda-opencv/</guid>
      <description>可通过以下命令安装 OpenCV： conda install -c menpo opencv</description>
    </item>
    
    <item>
      <title>BLWL[36] Ubuntu 安装显卡驱动时 No additional drivers available 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl36/</link>
      <pubDate>Mon, 14 Dec 2020 23:50:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl36/</guid>
      <description>新配置的 Ubuntu 炼丹工作站在通过 Software and Updates 中的 Additional Drivers 选项卡安装 GPU 显卡驱动时出现了 No additional drivers available 的问题。 解决方案如下。 sudo add-apt-repository ppa:xorg-edgers/ppa sudo apt-get update 完成后回到 Software and Updates 中的 Additional Drivers 选项卡</description>
    </item>
    
    <item>
      <title>BLWL[35] Ubuntu 上向日葵被连接时闪退问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl35/</link>
      <pubDate>Mon, 14 Dec 2020 23:18:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl35/</guid>
      <description>新配置的 Ubuntu 炼丹工作站上装的向日葵一被连接就闪退，查阅了一些资料后顺利解决了这个问题，具体方法如下。 sudo apt-get update sudo apt-get upgrade sudo apt-get install lightdm 安装 lightdm 的过程中会让选择</description>
    </item>
    
    <item>
      <title>压缩图表空间以调整 Latex 版面</title>
      <link>http://jonathanwayy.xyz/2020/latex_vspace/</link>
      <pubDate>Sun, 06 Dec 2020 23:51:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/latex_vspace/</guid>
      <description>很多会议论文都有特定的模板格式，并且在篇幅上有所限制，为了尽可能地多写一点内容，可以考虑在图像、表格、公式中利用 \vspace{} 来压缩垂直距离。 例如： \begin{figure*}[t] \vspace{-1.0cm}</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- &#39; xsrf&#39; argument missing from POST 解决方法</title>
      <link>http://jonathanwayy.xyz/2020/ldp1/</link>
      <pubDate>Thu, 12 Nov 2020 12:47:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/ldp1/</guid>
      <description>问题描述 Jupyter Notebook 保存时出现 ‘_xsrf’ argument missing from POST 错误，保存失败。 解决方法 刷新 Jupyter Notebook 的 home 界面即可，简单粗暴，亲测有效。</description>
    </item>
    
    <item>
      <title>花书 阅读笔记</title>
      <link>http://jonathanwayy.xyz/2020/flower-book-notes/</link>
      <pubDate>Mon, 05 Oct 2020 19:34:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/flower-book-notes/</guid>
      <description>Chapter 1 硬编码知识体系 —— 知识库方法（Cyc） 从原始数据中提取模式 —— 机器学习 简单的机器学习算法的性能很大程度上以来于给定数据的表示 很难知道该提</description>
    </item>
    
    <item>
      <title>Numpy散记 -- allclose函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-allclose/</link>
      <pubDate>Tue, 21 Apr 2020 13:09:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-allclose/</guid>
      <description>函数原型 numpy.allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False) 参数 a, b：用于比较的两个输入数组 rtol：float型，相对容忍系数（relative tolerance parameter） atol：fl</description>
    </item>
    
    <item>
      <title>Numpy散记 -- clip函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-clip/</link>
      <pubDate>Tue, 21 Apr 2020 12:54:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-clip/</guid>
      <description>函数原型 numpy.clip(a, a_min, a_max, out=None, **kwargs) 参数 a：数组 a_max：数组元素最大值 a_min：数组元素最小值 功能 np.clip()函数用于将数组元素的值保持在给定区间</description>
    </item>
    
    <item>
      <title>浅谈激活函数以零为中心的问题</title>
      <link>http://jonathanwayy.xyz/2020/zero-centered-active-function/</link>
      <pubDate>Wed, 15 Apr 2020 13:20:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/zero-centered-active-function/</guid>
      <description>本文主要探讨神经网络中的激活函数不是以零为中心（non-zero-centered）是否会导致神经网络收敛变慢，并讨论其背后的原因。 神经元 如</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 饱和激活函数</title>
      <link>http://jonathanwayy.xyz/2020/dl-notes1/</link>
      <pubDate>Wed, 04 Mar 2020 09:07:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/dl-notes1/</guid>
      <description>饱和激活函数 当自变量趋于正无穷时，若激活函数的导数趋于0,则称之为右饱和。 当自变量趋于负无穷时，若激活函数的导数趋于0,则称之为左饱和。 若一</description>
    </item>
    
    <item>
      <title>基于人脸检测的自动口罩/护目镜佩戴小程序</title>
      <link>http://jonathanwayy.xyz/2020/mask-wearing/</link>
      <pubDate>Wed, 29 Jan 2020 18:56:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/mask-wearing/</guid>
      <description>最近武汉的疫情闹得沸沸扬扬，大家出行都戴上了口罩预防被传染，很多人还给自己的社交媒体头像戴上了口罩。 为了省去P图时来回来去调整的麻烦，这里开</description>
    </item>
    
    <item>
      <title>Pytorch部分加载预训练ResNet-50模型作为Backbone</title>
      <link>http://jonathanwayy.xyz/2020/torch2/</link>
      <pubDate>Tue, 28 Jan 2020 00:08:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/torch2/</guid>
      <description>在写CV实(lian)验(dan)代码的时，经常需要使用预训练好的CNN模型作为自己模型的骨架网络(Backbone)，其中VGG-16和R</description>
    </item>
    
    <item>
      <title>Pytorch部分加载预训练VGG-16模型作为Backbone</title>
      <link>http://jonathanwayy.xyz/2020/torch1/</link>
      <pubDate>Sat, 25 Jan 2020 17:26:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/torch1/</guid>
      <description>在写CV实(lian)验(dan)代码的时，经常需要使用预训练好的CNN模型作为自己模型的骨架网络(Backbone)，其中VGG-16和R</description>
    </item>
    
  </channel>
</rss>
